{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import bs4\n",
    "import pypyodbc as podbc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas params\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.min_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to set a couple of variables that can be changed to reflect the current season and date throughout the script to prevent having to manually change things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_year = '2019-20'\n",
    "last_year = '2018-19'\n",
    "todays_date = '2020-12-22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Per-game values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build a function to scrape per-game values for a given season. In practice, we will only be scraping the *current* seaon's per-game values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape per-game values\n",
    "def scrape_per_game(season):\n",
    "    headers = {\n",
    "'Host': 'stats.nba.com',\n",
    "'Connection': 'keep-alive',\n",
    "'Accept': 'application/json, text/plain, */*',\n",
    "'x-nba-stats-token': 'true',\n",
    "'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "'x-nba-stats-origin': 'stats',\n",
    "'Referer': 'https://www.nba.com/',\n",
    "'Accept-Encoding': 'gzip, deflate, br',\n",
    "'Accept-Language': 'en-US,en;q=0.9'}\n",
    "\n",
    "    url = f\"https://stats.nba.com/stats/leaguedashplayerstats?College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType=Regular+Season&ShotClockRange=&StarterBench=&TeamID=0&TwoWay=0&VsConference=&VsDivision=&Weight=\"\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "\n",
    "    df = pd.DataFrame(r['resultSets'][0]['rowSet'], columns = r['resultSets'][0]['headers'])\n",
    "    df['Season'] = season\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create per_game, a DataFrame to hold per-game values for relevant seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we pull in the per-game values from prior seasons\n",
    "past = pd.read_csv(\"C:\\\\Users\\gsteele\\Other\\per_game_past.csv\")\n",
    "\n",
    "#Temporary, will NOT go into production\n",
    "past = past[past['Season'] != '2019-20']\n",
    "\n",
    "current = scrape_per_game(this_year)\n",
    "frame_list = [past,current]\n",
    "per_game = pd.concat(frame_list)\n",
    "\n",
    "#Calculate two-pointers\n",
    "per_game.insert(loc = 16, column = 'FG2M', value = (per_game.FGM - per_game.FG3M))\n",
    "per_game.insert(loc = 17, column = 'FG2A', value = (per_game.FGA - per_game.FG3A))\n",
    "\n",
    "#DraftKings average\n",
    "per_game.insert(loc = 1, column = 'draftkings', value = (\n",
    "        (per_game.FG3M*3.5)+(per_game.FG2M*2)+(per_game.FTM)+(per_game.REB*1.25)+(per_game.BLK*2)+(per_game.STL*2)\n",
    "        +(per_game.TOV*(-0.5))+(per_game.AST*1.5)\n",
    "        )\n",
    ")\n",
    "#FanDuel average\n",
    "per_game.insert(loc = 1, column = 'fanduel', value = (\n",
    "        (per_game.FG3M*3)+(per_game.FG2M*2)+(per_game.FTM)+(per_game.REB*1.2)+(per_game.BLK*2)+(per_game.STL*2)\n",
    "        +(per_game.TOV*(-1))+(per_game.AST*1.5)\n",
    "        )\n",
    ")\n",
    "\n",
    "per_game = per_game[['PLAYER_ID','PLAYER_NAME','Season','fanduel','draftkings','TEAM_ID','TEAM_ABBREVIATION','GP','MIN','PTS','FGM',\n",
    "                     'FGA','FG2M','FG2A','FG3M','FG3A','FG_PCT','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB','AST','TOV',\n",
    "                    'STL','BLK','PF','PFD','DD2','TD3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update matchup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function pulls down matchup data for a single in the current season, then concatenates into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_matchup_data(teamid):\n",
    "    headers = {\n",
    "'Host': 'stats.nba.com',\n",
    "'Connection': 'keep-alive',\n",
    "'Accept': 'application/json, text/plain, */*',\n",
    "'x-nba-stats-token': 'true',\n",
    "'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "'x-nba-stats-origin': 'stats',\n",
    "'Referer': f\"https://stats.nba.com/team/{teamid}/matchups/\",\n",
    "'Accept-Encoding': 'gzip, deflate, br',\n",
    "'Accept-Language': 'en-US,en;q=0.9'}\n",
    "\n",
    "    url = f\"https://stats.nba.com/stats/leagueseasonmatchups?DateFrom=&DateTo=&DefTeamID={teamid}&LeagueID=00&Outcome=&PORound=0&PerMode=Totals&Season=2019-20&SeasonType=Regular+Season\"\"\"\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "    df = pd.DataFrame(r['resultSets'][0]['rowSet'], columns = r['resultSets'][0]['headers'])\n",
    "    return df\n",
    "\n",
    "csv_list = []\n",
    "for team_id in range (1610612737,1610612768):\n",
    "    time.sleep(np.random.randint(0,5 + 1))\n",
    "    frame = scrape_matchup_data(team_id)\n",
    "    csv_list.append(frame)\n",
    "    \n",
    "new_matchups = pd.concat(csv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine the current season's matchup data with previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import matchup data\n",
    "old_matchups = pd.read_csv(r'c:\\users\\gsteele\\Other\\matchup_data.csv', low_memory = False)\n",
    "\n",
    "#The next line will be deleted BEFORE PRODUCTION\n",
    "old_matchups = old_matchups[old_matchups['SEASON_ID'] != '22019']\n",
    "\n",
    "#Combine current season with previous data\n",
    "matchups = [new_matchups,old_matchups]\n",
    "matchups_df = pd.concat(matchups)\n",
    "\n",
    "#Handle season naming conventions\n",
    "matchups_df.loc[matchups_df['SEASON_ID'] == '22017', 'SEASON_ID'] = '2017-18'\n",
    "matchups_df.loc[matchups_df['SEASON_ID'] == '22018', 'SEASON_ID'] = '2018-19'\n",
    "matchups_df.loc[matchups_df['SEASON_ID'] == '22019', 'SEASON_ID'] = '2019-20'\n",
    "\n",
    "#Calculate FG2M and FG2A\n",
    "matchups_df.insert(loc = 17, column = 'MATCHUP_FG2M', value = (matchups_df['MATCHUP_FGM'] - matchups_df['MATCHUP_FG3M']))\n",
    "matchups_df.insert(loc = 17, column = 'MATCHUP_FG2A', value = (matchups_df['MATCHUP_FGA'] - matchups_df['MATCHUP_FG3M']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matchups2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step will be to join matchup data to the per-game data. We'll also aggregate total possessions and possessions per game within a season for each player (\"offesnive\" player). We're also going to round up PARTIAL_POSS values below 0.5 up to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join per-game with matchup data\n",
    "matchups2 = pd.merge(left = per_game, right = matchups_df, \n",
    "                     how = 'left', left_on = ['PLAYER_ID','Season'], right_on = ['OFF_PLAYER_ID','SEASON_ID'])\n",
    "\n",
    "#Determining total possessions and possessions per game for offensive player\n",
    "matchups2.insert(loc = 7, column = 'total_possessions', value = \n",
    "                 (matchups2.groupby(['PLAYER_ID','Season'])['PARTIAL_POSS'].transform('sum')\n",
    "                 )\n",
    "                )\n",
    "\n",
    "matchups2.insert(loc = 8, column = 'poss_per_game', value = (matchups2['total_possessions']/(matchups2['GP_x'])))\n",
    "\n",
    "#rounding up values below a half-possession for a game\n",
    "matchups2['PARTIAL_POSS'].update(np.where(matchups2['PARTIAL_POSS']<0.5, 0.5, matchups2['PARTIAL_POSS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tat we know how many possessions per game each player plays, we can calculate their average per-possession vales for the given season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate per-possession values for offensive player\n",
    "matchups2.insert(loc = 9, column = 'fanduel_poss', value = (matchups2['fanduel']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 10, column = 'draftkings_poss', value = (matchups2['draftkings']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 11, column = 'PTS_poss', value = (matchups2['PTS']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 12, column = 'FGM_poss', value = (matchups2['FGM']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 13, column = 'FGA_poss', value = (matchups2['FGA']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 14, column = 'REB_poss', value = (matchups2['REB']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 15, column = 'OREB_poss', value = (matchups2['OREB']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 16, column = 'DREB_poss', value = (matchups2['DREB']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 17, column = 'AST_poss', value = (matchups2['AST']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 18, column = 'TOV_poss', value = (matchups2['TOV']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 19, column = 'STL_poss', value = (matchups2['STL']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 20, column = 'BLK_poss', value = (matchups2['BLK']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 21, column = 'FTM_poss', value = (matchups2['FTM']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 22, column = 'FTA_poss', value = (matchups2['FTA']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 21, column = 'FG3M_poss', value = (matchups2['FG3M']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 22, column = 'FG3A_poss', value = (matchups2['FG3A']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 21, column = 'FG2M_poss', value = (matchups2['FG2M']/matchups2['poss_per_game']))\n",
    "matchups2.insert(loc = 22, column = 'FG2A_poss', value = (matchups2['FG2A']/matchups2['poss_per_game']))\n",
    "\n",
    "#Drop matchups with zero possessions\n",
    "matchups2 = matchups2[matchups2['PARTIAL_POSS'] != 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draftkings and Fanduel have slightly different formulae, so we're going to create separate columns for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate fantasy points for each individual matchups\n",
    "#DraftKings\n",
    "matchups2.insert(loc = 1, column = 'MATCHUP_draftkings', value = (\n",
    "        (matchups2.MATCHUP_FG3M*3.5)+(matchups2.MATCHUP_FG2M*2)+(matchups2.MATCHUP_FTM)+\n",
    "        ((matchups2.REB_poss*matchups2.PARTIAL_POSS)*1.25)+\n",
    "        ((matchups2.BLK_poss*matchups2.PARTIAL_POSS)*2)+\n",
    "        ((matchups2.STL_poss*matchups2.PARTIAL_POSS)*2)+\n",
    "        (matchups2.MATCHUP_TOV*(-0.5))+(matchups2.MATCHUP_AST*1.5)\n",
    "        )\n",
    ")\n",
    "#FanDuel\n",
    "matchups2.insert(loc = 1, column = 'MATCHUP_fanduel', value = (\n",
    "        (matchups2.MATCHUP_FG3M*3)+(matchups2.MATCHUP_FG2M*2)+(matchups2.MATCHUP_FTM)+\n",
    "        ((matchups2.REB_poss*matchups2.PARTIAL_POSS)*1.2)+\n",
    "        ((matchups2.BLK_poss*matchups2.PARTIAL_POSS)*2)+\n",
    "        ((matchups2.STL_poss*matchups2.PARTIAL_POSS)*2)+\n",
    "        (matchups2.MATCHUP_TOV*(-1))+(matchups2.MATCHUP_AST*1.5)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the 'MATCHUP_' values and 'PARTIAL_POSS' to find per-possession values for each offesnive player/defensvie player matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate per-possession values for each matchup\n",
    "matchups2.insert(loc = 10, column = 'MATCHUP_fanduel_poss', value = (matchups2['MATCHUP_fanduel']/matchups2['PARTIAL_POSS']))        \n",
    "matchups2.insert(loc = 10, column = 'MATCHUP_draftkings_poss', value = (matchups2['MATCHUP_draftkings']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 11, column = 'MATCHUP_PTS_poss', value = (matchups2['PLAYER_PTS']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 12, column = 'MATCHUP_FGM_poss', value = (matchups2['MATCHUP_FGM']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 13, column = 'MATCHUP_FGA_poss', value = (matchups2['MATCHUP_FGA']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 17, column = 'MATCHUP_AST_poss', value = (matchups2['MATCHUP_AST']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 18, column = 'MATCHUP_TOV_poss', value = (matchups2['MATCHUP_TOV']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 20, column = 'MATCHUP_BLK_poss', value = (matchups2['MATCHUP_BLK']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 21, column = 'MATCHUP_FTM_poss', value = (matchups2['MATCHUP_FTM']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 22, column = 'MATCHUP_FTA_poss', value = (matchups2['MATCHUP_FTA']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 21, column = 'MATCHUP_FG3M_poss', value = (matchups2['MATCHUP_FG3M']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 22, column = 'MATCHUP_FG3A_poss', value = (matchups2['MATCHUP_FG3A']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 21, column = 'MATCHUP_FG2M_poss', value = (matchups2['MATCHUP_FG2M']/matchups2['PARTIAL_POSS']))\n",
    "matchups2.insert(loc = 22, column = 'MATCHUP_FG2A_poss', value = (matchups2['MATCHUP_FG2A']/matchups2['PARTIAL_POSS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NBA's increase in precision has produced unreliable data where a defender will be listed as coering a cerain offensive player for 2.83 possessions and the offensive player scoring 8 points during those possession. The following block uses some logic to estimate a more accurate 'PARTIAL_POSS' value for these cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54587\n",
      "20084\n",
      "358349\n",
      "38939\n",
      "3353\n",
      "319337\n"
     ]
    }
   ],
   "source": [
    "#Step 1\n",
    "#print(len(matchups2[matchups2['PARTIAL_POSS']%2 != 0]))\n",
    "print(len(matchups2[matchups2['MATCHUP_draftkings_poss']>2]))\n",
    "print(len(matchups2[matchups2['MATCHUP_draftkings_poss']>3]))\n",
    "print(len(matchups2[matchups2['PARTIAL_POSS']<2]))\n",
    "\n",
    "####Where PARTIAL_POSS goes to 1 decimal place\n",
    "#Repairing PARTIAL_POSS where value goes to 1 decimal place and is even\n",
    "matchups2['PARTIAL_POSS'].update(np.where(\n",
    "(        \n",
    "        (matchups2['PARTIAL_POSS']%2 != 0) & (matchups2['PARTIAL_POSS']%3 != 0) \n",
    "        & ((matchups2['PARTIAL_POSS']*10)%2 == 0)\n",
    "        & (matchups2['PARTIAL_POSS']<5)\n",
    "),\n",
    "#For cases where condition is true\n",
    "        round((matchups2['PARTIAL_POSS']%2)/2)\n",
    "        + matchups2['PARTIAL_POSS']\n",
    ",\n",
    "#For cases where condition is false, and PARTIAL_POSS is an integer, odd, or goes to 2 decimal places\n",
    "                                     matchups2['PARTIAL_POSS']\n",
    "                                    )\n",
    "                                    )\n",
    "\n",
    "#Repairing PARTIAL_POSS where value goes to 1 decimal place and is odd\n",
    "matchups2['PARTIAL_POSS'].update(np.where(\n",
    "(\n",
    "    (        \n",
    "        (matchups2['PARTIAL_POSS']%2 != 0) & (matchups2['PARTIAL_POSS']%3 != 0) \n",
    "        & ((matchups2['PARTIAL_POSS']*10)%2 != 0) & (matchups2['PARTIAL_POSS']<5)\n",
    "    )\n",
    "    #Second group of conditions\n",
    "    & (\n",
    "        ((matchups2['PARTIAL_POSS']*10)%3 == 0) \n",
    "        | ((matchups2['PARTIAL_POSS']*10)%5 == 0) \n",
    "        | ((matchups2['PARTIAL_POSS']*10)%7 == 0)\n",
    "    )\n",
    "),\n",
    "#For cases where condition is true\n",
    "        round((matchups2['PARTIAL_POSS']%2)/2)\n",
    "        + matchups2['PARTIAL_POSS']\n",
    ",\n",
    "#For cases where condition is false, and either 1) PARTIAL_POSS is integer or 2) PARTIAL_POSS has goes to 2 decimal places\n",
    "                                     matchups2['PARTIAL_POSS']\n",
    "                                    )\n",
    "                                    )\n",
    "\n",
    "\n",
    "#Repairing PARTIAL_POSS where value goes to 2 decimal places and is even\n",
    "matchups2['PARTIAL_POSS'].update(np.where(\n",
    "(        \n",
    "        (matchups2['PARTIAL_POSS']%2 != 0) & (matchups2['PARTIAL_POSS']%3 != 0) \n",
    "        & ((matchups2['PARTIAL_POSS']*100)%2 == 0)\n",
    "        & (matchups2['PARTIAL_POSS']<5)\n",
    "),\n",
    "#For cases where condition is true\n",
    "        (((matchups2['PARTIAL_POSS']*10)%2)/2)\n",
    "        + matchups2['PARTIAL_POSS']\n",
    ",\n",
    "#For cases where condition is false, and either 1) PARTIAL_POSS is integer or 2) PARTIAL_POSS is odd\n",
    "                                     matchups2['PARTIAL_POSS']\n",
    "                                    )\n",
    "                                    )\n",
    "\n",
    "\n",
    "matchups2['MATCHUP_fanduel_poss'].update(matchups2['MATCHUP_fanduel'].astype(float)/matchups2['PARTIAL_POSS'].astype(float))\n",
    "matchups2['MATCHUP_draftkings_poss'].update(matchups2['MATCHUP_draftkings'].astype(float)/matchups2['PARTIAL_POSS'].astype(float))\n",
    "\n",
    "\n",
    "### Where PARTIAL_POSS goes to 2 decimal places\n",
    "#Repairing PARTIAL_POSS where value goes to 2 decimal places and is odd, but divisin;e by a number less than 20\n",
    "matchups2['PARTIAL_POSS'].update(np.where(\n",
    "(\n",
    "    (        \n",
    "        (matchups2['PARTIAL_POSS']%2 != 0) & (matchups2['PARTIAL_POSS']%3 != 0) \n",
    "        & ((matchups2['PARTIAL_POSS']*100)%2 != 0) & (matchups2['PARTIAL_POSS']<5)\n",
    "    )\n",
    "    #Second group of conditions\n",
    "    & (\n",
    "        ((matchups2['PARTIAL_POSS']*100)%3 == 0) \n",
    "        | ((matchups2['PARTIAL_POSS']*100)%5 == 0) \n",
    "        | ((matchups2['PARTIAL_POSS']*100)%7 == 0)\n",
    "        | ((matchups2['PARTIAL_POSS']*100)%11 == 0)\n",
    "        | ((matchups2['PARTIAL_POSS']*100)%13 == 0)\n",
    "        | ((matchups2['PARTIAL_POSS']*100)%17 == 0)\n",
    "        | ((matchups2['PARTIAL_POSS']*100)%19 == 0)\n",
    "    )\n",
    "),\n",
    "#For cases where condition is true\n",
    "        ((round(((matchups2['PARTIAL_POSS']*10)%2)/2))\n",
    "        + (round(matchups2['PARTIAL_POSS'])))\n",
    ",\n",
    "#For cases where condition is false, and either 1) PARTIAL_POSS is integer or 2) PARTIAL_POSS has goes to 2 decimal places\n",
    "                                     matchups2['PARTIAL_POSS']\n",
    "                                    )\n",
    "                                    )\n",
    "\n",
    "\n",
    "matchups2['MATCHUP_fanduel_poss'].update(matchups2['MATCHUP_fanduel'].astype(float)/matchups2['PARTIAL_POSS'].astype(float))\n",
    "matchups2['MATCHUP_draftkings_poss'].update(matchups2['MATCHUP_draftkings'].astype(float)/matchups2['PARTIAL_POSS'].astype(float))\n",
    "\n",
    "#Repairing PARTIAL_POSS where MATCHUP_PTS_poss > 2 and PARTIAL_POSS < 5\n",
    "matchups2['PARTIAL_POSS'].update(np.where(   \n",
    "        (matchups2['MATCHUP_PTS_poss']>2) & (matchups2['PARTIAL_POSS']<5)\n",
    ",\n",
    "#For cases where condition is true\n",
    "        ((matchups2['PARTIAL_POSS']%2)/2)\n",
    "        + matchups2['PARTIAL_POSS']\n",
    ",\n",
    "#For cases where condition is false, and either 1) PARTIAL_POSS is integer or 2) PARTIAL_POSS has goes to 2 decimal places\n",
    "                                     matchups2['PARTIAL_POSS']\n",
    "                                    )\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "matchups2['MATCHUP_fanduel_poss'].update(matchups2['MATCHUP_fanduel'].astype(float)/matchups2['PARTIAL_POSS'].astype(float))\n",
    "matchups2['MATCHUP_draftkings_poss'].update(matchups2['MATCHUP_draftkings'].astype(float)/matchups2['PARTIAL_POSS'].astype(float))\n",
    "\n",
    "#print(len(matchups2[matchups2['PARTIAL_POSS']%2 != 0]))\n",
    "print(len(matchups2[matchups2['MATCHUP_draftkings_poss']>2]))\n",
    "print(len(matchups2[matchups2['MATCHUP_draftkings_poss']>3]))\n",
    "print(len(matchups2[matchups2['PARTIAL_POSS']<2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matchups2['MATCHUP_fanduel_poss'].update(matchups2['MATCHUP_fanduel'].astype(float)/matchups2['PARTIAL_POSS'])\n",
    "#matchups2['MATCHUP_draftkings_poss'].update(matchups2['MATCHUP_draftkings'].astype(float)/matchups2['PARTIAL_POSS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard-capping extreme results from small samples\n",
    "matchups2['MATCHUP_PTS_poss'].update(np.where(matchups2['MATCHUP_PTS_poss']>3, 3, matchups2['MATCHUP_PTS_poss']))\n",
    "matchups2['MATCHUP_fanduel_poss'].update(np.where(matchups2['MATCHUP_fanduel_poss']>3, 3, matchups2['MATCHUP_fanduel_poss']))\n",
    "matchups2['MATCHUP_draftkings_poss'].update(np.where(matchups2['MATCHUP_draftkings_poss']>3, 3, matchups2['MATCHUP_draftkings_poss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we compare the players performance against the given defender with his average performance to determine the differential caused by that defender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate differentials caused by defender\n",
    "matchups2.insert(loc = 11, column = 'MATCHUP_draftkings_diff', \n",
    "                 value = (matchups2['MATCHUP_draftkings_poss']-matchups2['draftkings_poss']))\n",
    "matchups2.insert(loc = 12, column = 'MATCHUP_fanduel_diff', \n",
    "                 value = (matchups2['MATCHUP_fanduel_poss']-matchups2['fanduel_poss']))\n",
    "matchups2.insert(loc = 11, column = 'MATCHUP_PTS_diff', value = (matchups2['MATCHUP_PTS_poss']-matchups2['PTS_poss']))\n",
    "matchups2.insert(loc = 12, column = 'MATCHUP_FGM_diff', value = (matchups2['MATCHUP_FGM_poss']-matchups2['FGM_poss']))\n",
    "matchups2.insert(loc = 13, column = 'MATCHUP_FGA_diff', value = (matchups2['MATCHUP_FGA_poss']-matchups2['FGA_poss']))\n",
    "matchups2.insert(loc = 17, column = 'MATCHUP_AST_diff', value = (matchups2['MATCHUP_AST_poss']-matchups2['AST_poss']))\n",
    "matchups2.insert(loc = 18, column = 'MATCHUP_TOV_diff', value = (matchups2['MATCHUP_TOV_poss']-matchups2['TOV_poss']))\n",
    "matchups2.insert(loc = 20, column = 'MATCHUP_BLK_diff', value = (matchups2['MATCHUP_BLK_poss']-matchups2['BLK_poss']))\n",
    "matchups2.insert(loc = 21, column = 'MATCHUP_FTM_diff', value = (matchups2['MATCHUP_FTM_poss']-matchups2['FTM_poss']))\n",
    "matchups2.insert(loc = 22, column = 'MATCHUP_FTA_diff', value = (matchups2['MATCHUP_FTA_poss']-matchups2['FTA_poss']))\n",
    "matchups2.insert(loc = 21, column = 'MATCHUP_FG3M_diff', value = (matchups2['MATCHUP_FG3M_poss']-matchups2['FG3M_poss']))\n",
    "matchups2.insert(loc = 22, column = 'MATCHUP_FG3A_diff', value = (matchups2['MATCHUP_FG3A_poss']-matchups2['FG3A_poss']))\n",
    "matchups2.insert(loc = 21, column = 'MATCHUP_FG2M_diff', value = (matchups2['MATCHUP_FG2M_poss']-matchups2['FG2M_poss']))\n",
    "matchups2.insert(loc = 22, column = 'MATCHUP_FG2A_diff', value = (matchups2['MATCHUP_FG2A_poss']-matchups2['FG2A_poss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data for today's games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Scrape schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function scrape_schedule pulls the schedule for a given day from the NBA schedule endpoint and indicates which team is home and which is away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_schedule ():\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "    'Referer': 'https://www.nba.com/',\n",
    "    }\n",
    "    url = 'https://cdn.nba.com/static/json/staticData/scheduleLeagueV2.json'\n",
    "    r = requests.get(url, headers=headers, allow_redirects = False).json()\n",
    "    date_list = r['leagueSchedule']['gameDates']\n",
    "    game_frames = []\n",
    "    for date in date_list:\n",
    "        for game in date['games']:\n",
    "            day = {key:value for key,value in game.items() if key == 'gameDateEst'}\n",
    "            game_dict = {key:value for key,value in game.items() if key == 'gameId'}\n",
    "            home = {key:value for key,value in game.items() if key == 'homeTeam'}\n",
    "            away = {key:value for key,value in game.items() if key == 'awayTeam'}\n",
    "            for team in home.values():\n",
    "                home_team = team['teamId']\n",
    "            for team in away.values():\n",
    "                away_team = team['teamId']\n",
    "            game_dict['Home'] = home_team\n",
    "            game_dict['Away'] = away_team\n",
    "            game_dict['Date'] = day.values()\n",
    "            df = pd.DataFrame.from_dict(game_dict, orient = 'index').swapaxes(\"index\",\"columns\")\n",
    "            game_frames.append(df)\n",
    "    schedule = pd.concat(game_frames).set_index('gameId')\n",
    "    schedule['Date'] = schedule['Date'].astype(str).copy()\n",
    "    schedule['Date'] = schedule['Date'].str[14:24].copy()\n",
    "    return schedule\n",
    "\n",
    "# Do not delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are here reshaping the output of scrape_schedule in order to essentially perform a self-join so that home team and away team are both associated iwth the same game id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull schedule and filter for today's date\n",
    "schedule = scrape_schedule()\n",
    "schedule['GAME_ID'] = schedule.index\n",
    "schedule.insert(loc = 4, column = 'Season',value = (\"20\"+schedule['GAME_ID'].str[3:5]+\"-\"+((schedule['GAME_ID'].str[3:5].astype(int))+1).astype(str)))\n",
    "\n",
    "#The following line only temporarily omitted and MUST be reinstated for production\n",
    "#today = schedule[schedule['Date'] == todays_date]\n",
    "\n",
    "#Temporary replacement for above line which must be REMOVED for production\n",
    "today = schedule\n",
    "\n",
    "#Format from home team's POV\n",
    "home = today.rename(columns = {\"Home\":\"Team\", \"Away\":\"Opponent\"})\n",
    "home.insert(loc = 5,column = 'Location',value = 'H')\n",
    "\n",
    "#Format from visitor's POV\n",
    "away = today.rename(columns = {\"Home\":\"Opponent\", \"Away\":\"Team\"})\n",
    "away = away[['Team','Opponent','Date','GAME_ID','Season']]\n",
    "away.insert(loc = 5,column = 'Location',value = 'A')\n",
    "\n",
    "#Combine home and away\n",
    "sched = [home,away]\n",
    "today2 = pd.concat(sched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape commonteamrosters\n",
    "def scrape_commonteamrosters():\n",
    "    headers = {\n",
    "'Host': 'stats.nba.com',\n",
    "'Connection': 'keep-alive',\n",
    "'Accept': 'application/json, text/plain, */*',\n",
    "'x-nba-stats-token': 'true',\n",
    "'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "'x-nba-stats-origin': 'stats',\n",
    "'Referer': 'https://www.nba.com/',\n",
    "'Accept-Encoding': 'gzip, deflate, br',\n",
    "'Accept-Language': 'en-US,en;q=0.9'}\n",
    "    \n",
    "    rosters = []\n",
    "    for team in range(1610612737,1610612768):\n",
    "        time.sleep(np.random.randint(0,5 + 1))\n",
    "        url = f\"https://stats.nba.com/stats/commonteamroster?LeagueID=00&Season=2019-20&TeamID={team}\"\n",
    "        r = requests.get(url, headers=headers).json()\n",
    "        df = pd.DataFrame(r['resultSets'][0]['rowSet'], columns = r['resultSets'][0]['headers'])\n",
    "        rosters.append(df)\n",
    "\n",
    "    return rosters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #  Matchups3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scraping the rosters, we join them to the schedule so that we have only the roster for teams playing today. With the rosters in hand, we need to join with matchups2_slim (thinner version with unecessary columns dropped) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get \"offensive\" rosters\n",
    "roster_list = scrape_commonteamrosters()\n",
    "rosters = pd.concat(roster_list)\n",
    "todays_rosters = pd.merge(left = today2, right = rosters, how = 'inner', left_on = ['Team'], right_on = ['TeamID'])\n",
    "\n",
    "#Review whether to use trimmed form or thick form here\n",
    "matchups2_slim = matchups2[['PLAYER_ID','PLAYER_NAME','Season','fanduel','draftkings','TEAM_ID','TEAM_ABBREVIATION',\n",
    "                    'fanduel_poss','draftkings_poss','total_possessions','poss_per_game','GP_x',\n",
    "                   'PTS_poss','FGM_poss','FGA_poss','FG3M_poss','FG3A_poss','FG2M_poss','FG2A_poss','FTM_poss',\n",
    "                   'FTA_poss','REB_poss','AST_poss','TOV_poss','STL_poss','BLK_poss']].drop_duplicates()\n",
    "matchups3 = pd.merge(left = matchups2_slim, right = todays_rosters, how = 'inner', left_on = ['PLAYER_ID'], right_on = ['PLAYER_ID'])\n",
    "matchups3 = matchups3[(matchups3['Season_x'] == this_year) | (matchups3['Season_x'] == last_year)].copy()\n",
    "matchups3 = matchups3.drop(['SEASON','LeagueID','PLAYER','PLAYER_SLUG','BIRTH_DATE','EXP','SCHOOL','NUM'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Matchups4, matchups5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are merging the roster for the \"defensive team\" with the rosters for the \"offensive team\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35881\n"
     ]
    }
   ],
   "source": [
    "#print(len(opponent))\n",
    "print(len(matchups3))\n",
    "#opponent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.04 GiB for an array with shape (22, 24671630) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6c6b9c31f6de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#Drop unnecessary columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m matchups4 = matchups4.drop(['Team_x','Opponent_x','Date_x','GAME_ID_x','Season_y','POSITION_x','HEIGHT_x','WEIGHT_x','AGE_x',\n\u001b[0m\u001b[0;32m     19\u001b[0m                            'PLAYER_SLUG','LeagueID','NUM','BIRTH_DATE','EXP','SCHOOL','TeamID_x','Location_y'], axis = 1)\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4162\u001b[0m         \"\"\"\n\u001b[1;32m-> 4163\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3922\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[1;31m# Case for non-unique axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4030\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4031\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4032\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4034\u001b[0m     def drop(\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4441\u001b[0m             )\n\u001b[0;32m   4442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4443\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4445\u001b[0m         \u001b[1;31m# if all axes that are requested to reindex are equal, then only copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5214\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5201\u001b[0m         \"\"\"\n\u001b[0;32m   5202\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5203\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5205\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5211\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5212\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    975\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1897\u001b[0m     \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[0;32m   1900\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m         )\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   1923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1925\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1926\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.04 GiB for an array with shape (22, 24671630) and data type float64"
     ]
    }
   ],
   "source": [
    "defenders = matchups2[['SEASON_ID','OFF_PLAYER_ID','OFF_PLAYER_NAME','DEF_PLAYER_ID','DEF_PLAYER_NAME','PARTIAL_POSS',\n",
    "                       'MATCHUP_fanduel_poss','MATCHUP_draftkings_poss','MATCHUP_PTS_poss','MATCHUP_FGM_poss','MATCHUP_FGA_poss',\n",
    "                      'MATCHUP_FG3M_poss','MATCHUP_FG3A_poss','MATCHUP_FG2M_poss','MATCHUP_FG2A_poss','MATCHUP_FTM_poss',\n",
    "                      'MATCHUP_FTA_poss','MATCHUP_AST_poss','MATCHUP_TOV_poss','REB_poss','STL_poss','BLK_poss',\n",
    "                       'MATCHUP_fanduel_diff','MATCHUP_draftkings_diff','MATCHUP_PTS_diff','MATCHUP_FGM_diff','MATCHUP_FGA_diff',\n",
    "                      'MATCHUP_FG3M_diff','MATCHUP_FG3A_diff','MATCHUP_FG2M_diff','MATCHUP_FG2A_diff','MATCHUP_FTM_diff',\n",
    "                      'MATCHUP_FTA_diff','MATCHUP_AST_diff','MATCHUP_TOV_diff']]\n",
    "\n",
    "#Join schedule to opponent roster\n",
    "opponent = pd.merge(left = today2, right = rosters, how = 'inner', left_on = ['Opponent'], right_on = ['TeamID'])\n",
    "\n",
    "#Join matchups3 to opponent\n",
    "matchups4 = pd.merge (left = matchups3, right = opponent, how = 'outer', left_on = ['TEAM_ID'], right_on = ['Team'])\n",
    "\n",
    "\n",
    "\n",
    "#Drop unnecessary columns\n",
    "matchups4 = matchups4.drop(['Team_x','Opponent_x','Date_x','GAME_ID_x','Season_y','POSITION_x','HEIGHT_x','WEIGHT_x','AGE_x',\n",
    "                           'PLAYER_SLUG','LeagueID','NUM','BIRTH_DATE','EXP','SCHOOL','TeamID_x','Location_y'], axis = 1)\n",
    "\n",
    "#Join matchups4 to defenders\n",
    "matchups5 = pd.merge(left = matchups4, right = defenders, \n",
    "                     how = 'inner', left_on = ['PLAYER_ID_x','PLAYER_ID_y'], right_on = ['OFF_PLAYER_ID','DEF_PLAYER_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to aggregate across every instacne of a pairing. For most offensvie player/defensive payer matchups, the two have faced each other in mroe than one game. So we no need to aggregate across games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups5.insert(loc = 35, column = 'PARTIAL_POSS2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['PARTIAL_POSS'].transform('sum')))\n",
    "matchups5.insert(loc = 36, column = 'MATCHUP_fanduel_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_fanduel_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 37, column = 'MATCHUP_draftkings_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_draftkings_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 38, column = 'MATCHUP_PTS_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_PTS_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 39, column = 'MATCHUP_FGM_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FGM_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 40, column = 'MATCHUP_FGA_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FGA_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 41, column = 'MATCHUP_FG2M_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG2M_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 42, column = 'MATCHUP_FG2A_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG2A_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 43, column = 'MATCHUP_FG3M_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG3M_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 44, column = 'MATCHUP_FG3A_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG3A_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 45, column = 'MATCHUP_FTM_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FTM_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 46, column = 'MATCHUP_FTA_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FTA_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 47, column = 'MATCHUP_AST_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_AST_diff'].transform('sum')))\n",
    "matchups5.insert(loc = 48, column = 'MATCHUP_TOV_diff2', value = (matchups5.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_TOV_diff'].transform('sum')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we update the \"per possession\" values for each matchup with the previosuly calculated values that aggregate across games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups5['PARTIAL_POSS'].update(matchups5['PARTIAL_POSS2'])\n",
    "matchups5['MATCHUP_fanduel_diff'].update(matchups5['MATCHUP_fanduel_diff2'])\n",
    "matchups5['MATCHUP_draftkings_diff'].update(matchups5['MATCHUP_draftkings_diff2'])\n",
    "matchups5['MATCHUP_PTS_diff'].update(matchups5['MATCHUP_PTS_diff2'])\n",
    "matchups5['MATCHUP_FGM_diff'].update(matchups5['MATCHUP_FGM_diff2'])\n",
    "matchups5['MATCHUP_FGA_diff'].update(matchups5['MATCHUP_FGA_diff2'])\n",
    "matchups5['MATCHUP_FG2M_diff'].update(matchups5['MATCHUP_FG2M_diff2'])\n",
    "matchups5['MATCHUP_FG2A_diff'].update(matchups5['MATCHUP_FG2A_diff2'])\n",
    "matchups5['MATCHUP_FG3M_diff'].update(matchups5['MATCHUP_FG3M_diff2'])\n",
    "matchups5['MATCHUP_FG3A_diff'].update(matchups5['MATCHUP_FG3A_diff2'])\n",
    "matchups5['MATCHUP_FTM_diff'].update(matchups5['MATCHUP_FTM_diff2'])\n",
    "matchups5['MATCHUP_FTA_diff'].update(matchups5['MATCHUP_FTA_diff2'])\n",
    "matchups5['MATCHUP_AST_diff'].update(matchups5['MATCHUP_AST_diff2'])\n",
    "matchups5['MATCHUP_TOV_diff'].update(matchups5['MATCHUP_TOV_diff2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matchups6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of matchups6 is to aggregate the box score *values* for each matchup. Previously, we have only aggregated the *differentials*, but not the simple number of FG3M, AST, TOV, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_raw = matchups2[['OFF_PLAYER_ID','DEF_PLAYER_ID','PLAYER_PTS','MATCHUP_FGM','MATCHUP_FGA','MATCHUP_FG2M',\n",
    "                         'MATCHUP_FG2A','MATCHUP_FG3M','MATCHUP_FG3A','MATCHUP_FTM','MATCHUP_FTA','MATCHUP_AST','MATCHUP_TOV',\n",
    "                        'MATCHUP_fanduel','MATCHUP_draftkings']]\n",
    "matchup_raw.insert(loc = 1, column = 'OFFENSIVE_PLAYER', value = matchup_raw['OFF_PLAYER_ID'])\n",
    "matchup_raw.insert(loc = 1, column = 'DEFENSIVE_PLAYER', value = matchup_raw['DEF_PLAYER_ID'])\n",
    "matchup_raw = matchup_raw.drop(['OFF_PLAYER_ID','DEF_PLAYER_ID'], axis = 1)\n",
    "\n",
    "#matchups 5 left join matchup_raw\n",
    "matchups6 = pd.merge(left = matchups5, right = matchup_raw, how = 'left', left_on = ['OFF_PLAYER_ID','DEF_PLAYER_ID',], right_on = ['OFFENSIVE_PLAYER','DEFENSIVE_PLAYER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups6.insert(loc = 36, column = 'MATCHUP_fanduel2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_fanduel'].transform('sum')))\n",
    "matchups6.insert(loc = 37, column = 'MATCHUP_draftkings2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_draftkings'].transform('sum')))\n",
    "matchups6.insert(loc = 38, column = 'MATCHUP_PTS2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['PLAYER_PTS'].transform('sum')))\n",
    "matchups6.insert(loc = 39, column = 'MATCHUP_FGM2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FGM'].transform('sum')))\n",
    "matchups6.insert(loc = 40, column = 'MATCHUP_FGA2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FGA'].transform('sum')))\n",
    "matchups6.insert(loc = 41, column = 'MATCHUP_FG2M2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG2M'].transform('sum')))\n",
    "matchups6.insert(loc = 42, column = 'MATCHUP_FG2A2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG2A'].transform('sum')))\n",
    "matchups6.insert(loc = 43, column = 'MATCHUP_FG3M2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG3M'].transform('sum')))\n",
    "matchups6.insert(loc = 44, column = 'MATCHUP_FG3A2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FG3A'].transform('sum')))\n",
    "matchups6.insert(loc = 45, column = 'MATCHUP_FTM2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FTM'].transform('sum')))\n",
    "matchups6.insert(loc = 46, column = 'MATCHUP_FTA2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_FTA'].transform('sum')))\n",
    "matchups6.insert(loc = 47, column = 'MATCHUP_AST2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_AST'].transform('sum')))\n",
    "matchups6.insert(loc = 48, column = 'MATCHUP_TOV2', value = (matchups6.groupby(['OFF_PLAYER_ID','DEF_PLAYER_ID'])['MATCHUP_TOV'].transform('sum')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the original fields with the aggregtd values so that we can drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups6['MATCHUP_fanduel'].update(matchups6['MATCHUP_fanduel2'])\n",
    "matchups6['MATCHUP_draftkings'].update(matchups6['MATCHUP_draftkings2'])\n",
    "matchups6['MATCHUP_FGM'].update(matchups6['MATCHUP_FGM2'])\n",
    "matchups6['MATCHUP_FGA'].update(matchups6['MATCHUP_FGA2'])\n",
    "matchups6['MATCHUP_FG2M'].update(matchups6['MATCHUP_FG2M2'])\n",
    "matchups6['MATCHUP_FG2A'].update(matchups6['MATCHUP_FG2A2'])\n",
    "matchups6['MATCHUP_FG3M'].update(matchups6['MATCHUP_FG3M2'])\n",
    "matchups6['MATCHUP_FG3A'].update(matchups6['MATCHUP_FG3A2'])\n",
    "matchups6['MATCHUP_FTM'].update(matchups6['MATCHUP_FTM2'])\n",
    "matchups6['MATCHUP_FTA'].update(matchups6['MATCHUP_FTA2'])\n",
    "matchups6['MATCHUP_AST'].update(matchups6['MATCHUP_AST2'])\n",
    "matchups6['MATCHUP_TOV'].update(matchups6['MATCHUP_TOV2'])\n",
    "\n",
    "\n",
    "matchups6.insert(loc = 117, column = 'MATCHUP_PTS', value = matchups6['MATCHUP_PTS2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update matchup per-possession values to include all possessions, regardless of season\n",
    "matchups6['MATCHUP_fanduel_poss'].update(matchups6['MATCHUP_fanduel']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_draftkings_poss'].update(matchups6['MATCHUP_draftkings']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_PTS_poss'].update(matchups6['MATCHUP_PTS']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FGM_poss'].update(matchups6['MATCHUP_FGM']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FGA_poss'].update(matchups6['MATCHUP_FGA']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FG3M_poss'].update(matchups6['MATCHUP_FG3M']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FG3A_poss'].update(matchups6['MATCHUP_FG3A']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FG2M_poss'].update(matchups6['MATCHUP_FG2M']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FG2A_poss'].update(matchups6['MATCHUP_FG2A']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FTM_poss'].update(matchups6['MATCHUP_FTM']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_FTA_poss'].update(matchups6['MATCHUP_FTA']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_AST_poss'].update(matchups6['MATCHUP_AST']/matchups6['PARTIAL_POSS'])\n",
    "matchups6['MATCHUP_TOV_poss'].update(matchups6['MATCHUP_TOV']/matchups6['PARTIAL_POSS'])\n",
    "\n",
    "\n",
    "matchups6 = matchups6.drop(['PLAYER_PTS'], axis = 1).drop_duplicates()\n",
    "matchups6 = matchups6[(matchups6['SEASON_ID'] == '2019-20') | (matchups6['SEASON_ID'] == '2018-19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard-capping unreliable per-possession values derived from PARTIAL_POSS < 1\n",
    "matchups6.loc[matchups6['MATCHUP_fanduel_poss'] > 3, 'MATCHUP_fanduel_poss'] = 3\n",
    "matchups6.loc[matchups6['MATCHUP_draftkings_poss'] > 3, 'MATCHUP_draftkings_poss'] = 3\n",
    "matchups6.loc[matchups6['MATCHUP_PTS_poss'] > 3, 'MATCHUP_PTS_poss'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Matchups7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups7 = matchups6.drop(['PARTIAL_POSS2','MATCHUP_fanduel2','MATCHUP_draftkings2','MATCHUP_PTS2','MATCHUP_FGM2',\n",
    "                            'MATCHUP_FGA2','MATCHUP_FG2M2','MATCHUP_FG2A2','MATCHUP_FG3M2','MATCHUP_FG3A2','MATCHUP_FTM2',\n",
    "                           'MATCHUP_FTA2','MATCHUP_AST2','MATCHUP_TOV2','MATCHUP_fanduel_diff2','MATCHUP_draftkings_diff2',\n",
    "                           'MATCHUP_PTS_diff2','MATCHUP_FGM_diff2','MATCHUP_FGA_diff2','MATCHUP_FG2M_diff2',\n",
    "                            'MATCHUP_FG2A_diff2','MATCHUP_FG3M_diff2','MATCHUP_FG3A_diff2','MATCHUP_FTM_diff2',\n",
    "                           'MATCHUP_FTA_diff2','MATCHUP_AST_diff2','MATCHUP_TOV_diff2','OFFENSIVE_PLAYER',\n",
    "                           'DEFENSIVE_PLAYER','REB_poss_y','STL_poss_y','BLK_poss_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe game_counter is a sub-table used to determine how much to weight this year's data relative to last year's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Building separate df to derive weights\n",
    "game_counter = matchups3[['PLAYER_ID','Season_x','GP_x','PTS_poss','FGM_poss','FGA_poss','FG2M_poss','FG2A_poss',\n",
    "                         'FG3M_poss','FG3A_poss','FTM_poss','FTA_poss','AST_poss','REB_poss','TOV_poss','STL_poss',\n",
    "                         'BLK_poss','fanduel_poss','draftkings_poss','PLAYER_NAME']].drop_duplicates()\n",
    "\n",
    "game_counter.insert(loc = 3, column = 'weight', value = \n",
    "    (game_counter['GP_x'] / (game_counter.groupby(['PLAYER_ID'])['GP_x'].transform('sum'))))\n",
    "game_counter = game_counter.rename(mapper = {\"PLAYER_ID\":\"ID\",\"Season_x\":\"SEASON_ID\"}, axis = 1)\n",
    "game_counter = game_counter.drop('GP_x', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derive weighting for each stat in each season\n",
    "game_counter['fd'] = game_counter['fanduel_poss']*game_counter['weight']\n",
    "game_counter['dk'] = game_counter['draftkings_poss']*game_counter['weight']\n",
    "game_counter['pts'] = game_counter['PTS_poss']*game_counter['weight']\n",
    "game_counter['fgm'] = game_counter['FGM_poss']*game_counter['weight']\n",
    "game_counter['fga'] = game_counter['FGA_poss']*game_counter['weight']\n",
    "game_counter['fg2m'] = game_counter['FG2M_poss']*game_counter['weight']\n",
    "game_counter['fg2a'] = game_counter['FG2A_poss']*game_counter['weight']\n",
    "game_counter['fg3m'] = game_counter['FG3M_poss']*game_counter['weight']\n",
    "game_counter['fg3a'] = game_counter['FG3A_poss']*game_counter['weight']\n",
    "game_counter['ftm'] = game_counter['FTM_poss']*game_counter['weight']\n",
    "game_counter['fta'] = game_counter['FTA_poss']*game_counter['weight']\n",
    "game_counter['reb'] = game_counter['REB_poss']*game_counter['weight']\n",
    "game_counter['ast'] = game_counter['AST_poss']*game_counter['weight']\n",
    "game_counter['tov'] = game_counter['TOV_poss']*game_counter['weight']\n",
    "game_counter['stl'] = game_counter['STL_poss']*game_counter['weight']\n",
    "game_counter['blk'] = game_counter['BLK_poss']*game_counter['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating weighted averages\n",
    "game_counter['fanduel_poss'].update(game_counter.groupby(['ID'])['fd'].transform('sum'))\n",
    "game_counter['draftkings_poss'].update(game_counter.groupby(['ID'])['dk'].transform('sum'))\n",
    "game_counter['PTS_poss'].update(game_counter.groupby(['ID'])['pts'].transform('sum'))\n",
    "game_counter['FGM_poss'].update(game_counter.groupby(['ID'])['fgm'].transform('sum'))\n",
    "game_counter['FGA_poss'].update(game_counter.groupby(['ID'])['fga'].transform('sum'))\n",
    "game_counter['FG2M_poss'].update(game_counter.groupby(['ID'])['fg2m'].transform('sum'))\n",
    "game_counter['FG2A_poss'].update(game_counter.groupby(['ID'])['fg2a'].transform('sum'))\n",
    "game_counter['FG3M_poss'].update(game_counter.groupby(['ID'])['fg3m'].transform('sum'))\n",
    "game_counter['FG3A_poss'].update(game_counter.groupby(['ID'])['fg3a'].transform('sum'))\n",
    "game_counter['FTM_poss'].update(game_counter.groupby(['ID'])['ftm'].transform('sum'))\n",
    "game_counter['FTA_poss'].update(game_counter.groupby(['ID'])['fta'].transform('sum'))\n",
    "game_counter['AST_poss'].update(game_counter.groupby(['ID'])['ast'].transform('sum'))\n",
    "game_counter['TOV_poss'].update(game_counter.groupby(['ID'])['tov'].transform('sum'))\n",
    "game_counter['REB_poss'].update(game_counter.groupby(['ID'])['reb'].transform('sum'))\n",
    "game_counter['STL_poss'].update(game_counter.groupby(['ID'])['stl'].transform('sum'))\n",
    "game_counter['BLK_poss'].update(game_counter.groupby(['ID'])['blk'].transform('sum'))\n",
    "\n",
    "#Renaming\n",
    "game_counter = game_counter.rename(columns = {'fanduel_poss':'baseline_fanduel','draftkings_poss':'baseline_draftkings',\n",
    "        'PTS_poss':'baseline_pts','FGM_poss':'baseline_fgm','FGA_poss':'baseline_fga','FG2M_poss':'baseline_fg2m',\n",
    "        'FG3M_poss':'baseline_fg3m','FG3A_poss':'baseline_fg3a','FTM_poss':'baseline_ftm','FTA_poss':'baseline_fta',\n",
    "        'AST_poss':'baseline_ast','TOV_poss':'baseline_tov','REB_poss_x':'baseline_reb','STL_poss_x':'baseline_stl',\n",
    "        'BLK_poss_x':'baseline_blk','FG2M_poss':'baseline_fg2m'})\n",
    "\n",
    "\n",
    "#Dropping unecessary columns\n",
    "game_counter = game_counter.drop(['SEASON_ID','weight','fd','dk','pts','fgm','fga','fg2m','fg2a','fg3m','fg3a','ftm','fta','reb',\n",
    "                                 'ast','tov','stl','blk'], axis = 1)\n",
    "game_counter = game_counter.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Take in only row for current season in matchups7\n",
    "matchups7 = matchups7[matchups7['Season_x'] == this_year]\n",
    "#matchups7 = matchups7.drop(columns = ['SEASON_ID']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Matchups8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've weighted this year vs last year, we know how much we should realistically expect each player to produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining weights to matchups7\n",
    "matchups8 = pd.merge(left = matchups7, right = game_counter,how = 'inner', left_on = ['PLAYER_ID_x'], \n",
    "                     right_on = ['ID'])\n",
    "\n",
    "matchups8.insert(loc = 101, column = 'total_defensive_impact_fanduel',\n",
    "                 value = matchups8.groupby(['PLAYER_ID_x','Opponent_y'])['MATCHUP_fanduel_diff'].transform('sum'))\n",
    "matchups8.insert(loc = 101, column = 'total_defensive_impact_draftkings',\n",
    "                 value = matchups8.groupby(['OFF_PLAYER_ID','Opponent_y'])['MATCHUP_draftkings_diff'].transform('sum'))\n",
    "matchups8.insert(loc = 101, column = 'total_defensive_impact_pts',\n",
    "                 value = matchups8.groupby(['OFF_PLAYER_ID','Opponent_y'])['MATCHUP_PTS_diff'].transform('sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating forecasted effect for individual defender\n",
    "matchups8.insert(loc = 101, column = 'total_defensive_poss',\n",
    "                 value = matchups8.groupby(['OFF_PLAYER_ID','Opponent_y'])['PARTIAL_POSS'].transform('sum'))\n",
    "matchups8.insert(loc = 101, column = 'individual_defender_impact_fanduel',\n",
    "                 value = (matchups8['poss_per_game']*\n",
    "                          (matchups8['MATCHUP_fanduel_diff']/matchups8['PARTIAL_POSS'])*\n",
    "                          (matchups8['PARTIAL_POSS']/matchups8['total_defensive_poss'])\n",
    "                         )\n",
    "                )\n",
    "matchups8.insert(loc = 101, column = 'individual_defender_impact_draftkings',\n",
    "                 value = (matchups8['poss_per_game']*\n",
    "                          (matchups8['MATCHUP_draftkings_diff']/matchups8['PARTIAL_POSS'])*\n",
    "                          (matchups8['PARTIAL_POSS']/matchups8['total_defensive_poss'])\n",
    "                         )\n",
    "                )\n",
    "matchups8.insert(loc = 101, column = 'individual_defender_impact_pts',\n",
    "                 value = (matchups8['poss_per_game']*\n",
    "                          (matchups8['MATCHUP_PTS_diff']/matchups8['PARTIAL_POSS'])*\n",
    "                          (matchups8['PARTIAL_POSS']/matchups8['total_defensive_poss'])\n",
    "                         )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregating effect across offensive player\n",
    "matchups8.insert(loc = 100, column = 'impact_of_defenders_fanduel', \n",
    "                 value = matchups8.groupby(['PLAYER_ID_x'])['individual_defender_impact_fanduel'].transform('sum'))\n",
    "matchups8.insert(loc = 100, column = 'impact_of_defenders_draftkings', \n",
    "                 value = matchups8.groupby(['PLAYER_ID_x'])['individual_defender_impact_draftkings'].transform('sum'))\n",
    "matchups8.insert(loc = 100, column = 'impact_of_defenders_pts', \n",
    "                 value = matchups8.groupby(['PLAYER_ID_x'])['individual_defender_impact_pts'].transform('sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find predicted values\n",
    "matchups8.insert(loc = 1, column = 'predicted_fanduel', \n",
    "                 value = matchups8['impact_of_defenders_fanduel'] + (matchups8['baseline_fanduel']*matchups8['poss_per_game']))\n",
    "matchups8.insert(loc = 1, column = 'predicted_draftkings', \n",
    "                 value = matchups8['impact_of_defenders_draftkings'] + (matchups8['baseline_draftkings']*matchups8['poss_per_game']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll push the predicted outcomes to a csv for comparison with observed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups8.to_csv(f\"C:\\\\Users\\gsteele\\Other\\predicted_values\\\\{todays_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#matchups8['predicted_draftkings']-matchups8['draftkings']\n",
    "out = (matchups8['predicted_fanduel'] - matchups8['fanduel']).sort_values().drop_duplicates()\n",
    "out\n",
    "#((matchups8['baseline_fanduel']*matchups8['poss_per_game']) - matchups8['fanduel']).round(2).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Isolating the problem in the calculation of 'impact_of_defenders_fanduel/draftkings'\n",
    "#matchups8[matchups8['impact_of_defenders_fanduel'] < 0]#['OFF_PLAYER_NAME','DEF_PLAYER_NAME','MATCHUP_fanduel_diff','PARTIAL_POSS']]\n",
    "#(matchups8['fanduel_poss']-matchups8['baseline_fanduel']).sort_values().drop_duplicates()\n",
    "#matchups7['Season_x'].value_counts()\n",
    "#(matchups8['predicted_fanduel'] - matchups8['fanduel']).drop_duplicates().sort_values()\n",
    "matchups8.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This appears to be producing inacurate results in the \"(matchups8['baseline_fanduel']*matchups8['poss_per_game']))\" portion. \n",
    "#Need to review both of these values, and/or use simple season average + defensive effect \n",
    "\n",
    "matchups8.insert(loc = 1, column = 'predicted_fanduel', \n",
    "                 value = matchups8['impact_of_defenders_fanduel'] + (matchups8['baseline_fanduel']*matchups8['poss_per_game']))\n",
    "matchups8.insert(loc = 1, column = 'predicted_draftkings', \n",
    "                 value = matchups8['impact_of_defenders_draftkings'] + (matchups8['baseline_draftkings']*matchups8['poss_per_game']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# game_counter is producing errant values for baseline_fanduel and baseline_draftkings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ONE** problem is that game_counter is taking only data from teams playing today, so players who played for a team last year that isn't playing today are having their previous season data dropped. This is not **the** problem which is causing the values to be too high. Cell below demonstrates that fantasy_poss values are much lower for 2019-20 than for 2018-19.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def matchupteam(teamid,season):\n",
    "    headers = {\n",
    "'Host': 'stats.nba.com',\n",
    "'Connection': 'keep-alive',\n",
    "'Accept': 'application/json, text/plain, */*',\n",
    "'x-nba-stats-token': 'true',\n",
    "'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "'x-nba-stats-origin': 'stats',\n",
    "'Referer': f\"https://stats.nba.com/team/{teamid}/matchups/\",\n",
    "'Accept-Encoding': 'gzip, deflate, br',\n",
    "'Accept-Language': 'en-US,en;q=0.9'}\n",
    "\n",
    "    url = f\"https://stats.nba.com/stats/leagueseasonmatchups?DateFrom=&DateTo=&DefTeamID={teamid}&LeagueID=00&Outcome=&PORound=0&PerMode=Totals&Season={season}&SeasonType=Regular+Season\"\"\"\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "    df = pd.DataFrame(r['resultSets'][0]['rowSet'], columns = r['resultSets'][0]['headers'])\n",
    "    df.to_csv(f\"C:\\\\Users\\gsteele\\Other\\matchups\\\\{season}_matchups_{teamid}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for season in ('2017-18','2018-19','2019-20'):\n",
    "    for teamid in range (1610612737,1610612768):\n",
    "        time.sleep(2.3)\n",
    "        matchupteam(teamid,season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = r'C:\\Users\\gsteele\\Other\\matchups'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "csv_list = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    csv_list.append(df)\n",
    "\n",
    "df2 = pd.concat(csv_list, axis=0, ignore_index=True)\n",
    "\n",
    "df2.to_csv(\"C:\\\\Users\\gsteele\\Other\\matchups\\\\all_matchups.csv\", index=False, encoding='ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import\n",
    "new_format = pd.read_csv(r'C:\\Users\\gsteele\\other\\matchups\\all_matchups.csv', low_memory = False)\n",
    "old_format = pd.read_csv(r'C:\\users\\gsteele\\Other\\old_matchups.csv', low_memory = False)\n",
    "\n",
    "#Clean old_format\n",
    "old_format_df = old_format[(old_format['SEASON_ID'] == '2013-14')\n",
    "                          | (old_format['SEASON_ID'] == '2014-15')\n",
    "                          | (old_format['SEASON_ID'] == '2015-16')\n",
    "                          | (old_format['SEASON_ID'] == '2016-17')\n",
    "                          ]\n",
    "\n",
    "#Create/rename columns to match new_format\n",
    "old_format_df.insert(loc = 1, column = 'PARTIAL_POSS', value = old_format_df['POSS'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_AST', value = old_format_df['AST'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_TOV', value = old_format_df['TOV'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_BLK', value = old_format_df['BLK'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FGM', value = old_format_df['FGM'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FGA', value = old_format_df['FGA'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FG_PCT', value = old_format_df['FG_PCT'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FG3M', value = old_format_df['FG3M'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FG3A', value = old_format_df['FG3A'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FG3_PCT', value = old_format_df['FG3_PCT'])\n",
    "old_format_df.insert(loc = 1, column = 'HELP_FGM', value = np.nan)\n",
    "old_format_df.insert(loc = 1, column = 'HELP_FGA', value = np.nan)\n",
    "old_format_df.insert(loc = 1, column = 'HELP_FG_PERC', value = np.nan)\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FTM', value = old_format_df['FTM'])\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_FTA', value = (old_format_df['SFL']*2))\n",
    "old_format_df.insert(loc = 1, column = 'GP', value = np.nan)\n",
    "old_format_df.insert(loc = 1, column = 'MATCHUP_MIN', value = (old_format_df['POSS'].astype(int)/2))\n",
    "\n",
    "#Order columns correctly\n",
    "new_df = new_format.drop('Unnamed: 0',axis=1)\n",
    "old_df = old_format_df[['SEASON_ID','OFF_PLAYER_ID','OFF_PLAYER_NAME','DEF_PLAYER_ID','DEF_PLAYER_NAME','GP','MATCHUP_MIN',\n",
    "                       'PARTIAL_POSS','PLAYER_PTS','TEAM_PTS','MATCHUP_AST','MATCHUP_TOV','MATCHUP_BLK','MATCHUP_FGM',\n",
    "                        'MATCHUP_FGA','MATCHUP_FG_PCT','MATCHUP_FG3M','MATCHUP_FG3A','MATCHUP_FG3_PCT',\n",
    "                       'HELP_BLK','HELP_FGM','HELP_FGA','HELP_FG_PERC','MATCHUP_FTM','MATCHUP_FTA','SFL']]\n",
    "data_list = [new_df,old_df]\n",
    "\n",
    "#Concatenate, then push out csv\n",
    "matchup_data = pd.concat(data_list)\n",
    "matchup_data.to_csv(r'c:\\users\\gsteele\\Other\\matchup_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
